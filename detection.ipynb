{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-29T07:06:15.692758Z","iopub.status.busy":"2024-05-29T07:06:15.692016Z","iopub.status.idle":"2024-05-29T07:06:22.908670Z","shell.execute_reply":"2024-05-29T07:06:22.907689Z","shell.execute_reply.started":"2024-05-29T07:06:15.692726Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Projects\\Machine Learning Technical Assessment\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np \n","import pandas as pd\n","import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:22.910597Z","iopub.status.busy":"2024-05-29T07:06:22.910163Z","iopub.status.idle":"2024-05-29T07:06:22.988866Z","shell.execute_reply":"2024-05-29T07:06:22.987998Z","shell.execute_reply.started":"2024-05-29T07:06:22.910571Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Language</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>στη Γαλλία νωρίτερα ραντεβού χρησιμοποιήθηκε α...</td>\n","      <td>Greek</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>e con ciò lei salì nella sua carrozza e senza ...</td>\n","      <td>Italian</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>buna değmez.</td>\n","      <td>Turkish</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Viktiga skillnader är att i en wiki lagras sid...</td>\n","      <td>Sweedish</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>تعرف على ما إذا كان شخص ما يقول نكتة رائعة يمك...</td>\n","      <td>Arabic</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Text  Language\n","0  στη Γαλλία νωρίτερα ραντεβού χρησιμοποιήθηκε α...     Greek\n","1  e con ciò lei salì nella sua carrozza e senza ...   Italian\n","2                                       buna değmez.   Turkish\n","3  Viktiga skillnader är att i en wiki lagras sid...  Sweedish\n","4  تعرف على ما إذا كان شخص ما يقول نكتة رائعة يمك...    Arabic"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('Language_det_train.csv')\n","df.head()"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:22.990747Z","iopub.status.busy":"2024-05-29T07:06:22.990029Z","iopub.status.idle":"2024-05-29T07:06:23.005723Z","shell.execute_reply":"2024-05-29T07:06:23.004647Z","shell.execute_reply.started":"2024-05-29T07:06:22.990714Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Language\n","English       1316\n","French         963\n","Spanish        778\n","Portugeese     702\n","Italian        663\n","Russian        657\n","Sweedish       642\n","Malayalam      564\n","Dutch          519\n","Arabic         509\n","Turkish        450\n","German         446\n","Tamil          446\n","Danish         407\n","Kannada        351\n","Greek          347\n","Hindi           60\n","Name: count, dtype: int64"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["df['Language'].value_counts()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:23.009412Z","iopub.status.busy":"2024-05-29T07:06:23.008555Z","iopub.status.idle":"2024-05-29T07:06:23.019628Z","shell.execute_reply":"2024-05-29T07:06:23.018813Z","shell.execute_reply.started":"2024-05-29T07:06:23.009383Z"},"trusted":true},"outputs":[],"source":["# encode the columns Languages to ids  \n","df['Language'] = df['Language'].astype('category')\n","df['Language'] = df['Language'].cat.codes"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:23.021034Z","iopub.status.busy":"2024-05-29T07:06:23.020758Z","iopub.status.idle":"2024-05-29T07:06:23.028621Z","shell.execute_reply":"2024-05-29T07:06:23.027734Z","shell.execute_reply.started":"2024-05-29T07:06:23.021010Z"},"trusted":true},"outputs":[],"source":["class TextClassificationDataset(Dataset):\n","    \n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","    def __len__(self):\n","        return len(self.texts)\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n","        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:23.030201Z","iopub.status.busy":"2024-05-29T07:06:23.029570Z","iopub.status.idle":"2024-05-29T07:06:23.041679Z","shell.execute_reply":"2024-05-29T07:06:23.040766Z","shell.execute_reply.started":"2024-05-29T07:06:23.030167Z"},"trusted":true},"outputs":[],"source":["class MultiLingualClassifier(nn.Module):\n","    def __init__(self, bert_model_name, num_classes):\n","        super(MultiLingualClassifier, self).__init__()\n","        self.bert = AutoModel.from_pretrained(bert_model_name)\n","        self.dropout = nn.Dropout(0.1)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","            pooled_output = outputs.pooler_output\n","            x = self.dropout(pooled_output)\n","            logits = self.fc(x)\n","            return logits"]},{"cell_type":"markdown","metadata":{},"source":["## why CrossEntropyLoss?\n","\n","- **cross-entropy**: measures the difference between the discovered probability distribution of a classification model and the predicted values.\n","- as this is a mulitclass classification problem CrossEntropy losss is the most popular loss function.\n","- also it is differentiable so it can help in the optimization phase."]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:13:34.201672Z","iopub.status.busy":"2024-05-29T07:13:34.200786Z","iopub.status.idle":"2024-05-29T07:13:34.208273Z","shell.execute_reply":"2024-05-29T07:13:34.207120Z","shell.execute_reply.started":"2024-05-29T07:13:34.201636Z"},"trusted":true},"outputs":[],"source":["def train(model, data_loader, optimizer, device):\n","    model.train()\n","    # loop through the training dataloader\n","    for batch in data_loader:\n","        model.zero_grad()\n","        # move input ids and attention masks to the same device as the model\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        loss = nn.CrossEntropyLoss()(outputs, torch.Tensor.long(labels))\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:23.054742Z","iopub.status.busy":"2024-05-29T07:06:23.054471Z","iopub.status.idle":"2024-05-29T07:06:23.063385Z","shell.execute_reply":"2024-05-29T07:06:23.062422Z","shell.execute_reply.started":"2024-05-29T07:06:23.054718Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, data_loader, device):\n","    model.eval()\n","    predictions = []\n","    actual_labels = []\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            _, preds = torch.max(outputs, dim=1)\n","            predictions.extend(preds.cpu().tolist())\n","            actual_labels.extend(labels.cpu().tolist())\n","    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:23.064839Z","iopub.status.busy":"2024-05-29T07:06:23.064505Z","iopub.status.idle":"2024-05-29T07:06:23.076815Z","shell.execute_reply":"2024-05-29T07:06:23.075965Z","shell.execute_reply.started":"2024-05-29T07:06:23.064806Z"},"trusted":true},"outputs":[],"source":["def predict_sentiment(text, model, tokenizer, device, max_length=128):\n","#     model.eval()\n","    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n","    input_ids = encoding['input_ids'].to(device)\n","    attention_mask = encoding['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            _, preds = torch.max(outputs, dim=1)\n","    return preds"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:06:26.268968Z","iopub.status.busy":"2024-05-29T07:06:26.268599Z","iopub.status.idle":"2024-05-29T07:06:26.274273Z","shell.execute_reply":"2024-05-29T07:06:26.273101Z","shell.execute_reply.started":"2024-05-29T07:06:26.268938Z"},"trusted":true},"outputs":[],"source":["# Set up parameters\n","model_id = 'amberoad/bert-multilingual-passage-reranking-msmarco'\n","num_classes = 17\n","max_length = 128\n","batch_size = 32\n","num_epochs = 4\n","learning_rate = 2e-5"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:07:07.965311Z","iopub.status.busy":"2024-05-29T07:07:07.964476Z","iopub.status.idle":"2024-05-29T07:07:07.973382Z","shell.execute_reply":"2024-05-29T07:07:07.972179Z","shell.execute_reply.started":"2024-05-29T07:07:07.965275Z"},"trusted":true},"outputs":[],"source":["texts, labels = df['Text'].values, df['Language'].values\n","train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:07:09.826483Z","iopub.status.busy":"2024-05-29T07:07:09.825979Z","iopub.status.idle":"2024-05-29T07:07:13.022000Z","shell.execute_reply":"2024-05-29T07:07:13.021196Z","shell.execute_reply.started":"2024-05-29T07:07:09.826447Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_id)\n","train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n","val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:07:13.023809Z","iopub.status.busy":"2024-05-29T07:07:13.023527Z","iopub.status.idle":"2024-05-29T07:07:53.793543Z","shell.execute_reply":"2024-05-29T07:07:53.792728Z","shell.execute_reply.started":"2024-05-29T07:07:13.023785Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MultiLingualClassifier(model_id, num_classes).to(device)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:08:25.965878Z","iopub.status.busy":"2024-05-29T07:08:25.965539Z","iopub.status.idle":"2024-05-29T07:08:25.975865Z","shell.execute_reply":"2024-05-29T07:08:25.974909Z","shell.execute_reply.started":"2024-05-29T07:08:25.965851Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Projects\\Machine Learning Technical Assessment\\env\\Lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"ename":"NameError","evalue":"name 'train_dataloader' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m----> 2\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m) \u001b[38;5;241m*\u001b[39m num_epochs\n\u001b[0;32m      3\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(optimizer, num_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_training_steps\u001b[38;5;241m=\u001b[39mtotal_steps)\n","\u001b[1;31mNameError\u001b[0m: name 'train_dataloader' is not defined"]}],"source":["optimizer = AdamW(model.parameters(), lr=learning_rate)\n","total_steps = len(train_dataloader) * num_epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:13:43.823653Z","iopub.status.busy":"2024-05-29T07:13:43.822828Z","iopub.status.idle":"2024-05-29T07:20:17.158700Z","shell.execute_reply":"2024-05-29T07:20:17.157634Z","shell.execute_reply.started":"2024-05-29T07:13:43.823619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[68], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     accuracy, report \u001b[38;5;241m=\u001b[39m evaluate(model, val_dataloader, device)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[1;32mIn[53], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, scheduler, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(outputs, torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mlong(labels))\n\u001b[1;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     13\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[1;32md:\\Projects\\Machine Learning Technical Assessment\\env\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\Projects\\Machine Learning Technical Assessment\\env\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\Projects\\Machine Learning Technical Assessment\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train(model, train_dataloader, optimizer, device)\n","    accuracy, report = evaluate(model, val_dataloader, device)\n","    print(f\"Validation Accuracy: {accuracy:.4f}\")\n","    print(report)"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["id2lang = {3: 'English', 4:'French',13:'Spanish', 11:\"Portugeese\", \n","8:\"Italian\", 12: \"Russian\", 14: \"Sweedish\", 10:\"Malayalam\", 2: \"Dutch\",\n"," 0: \"Arabic\", 16:\"Turkish\", 5: \"German\", 15: \"Tamil\", 1: \"Danish\", 9: \"Kannada\", 6: \"Greek\", 7: \"Hindi\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:29:21.273100Z","iopub.status.busy":"2024-05-29T07:29:21.272246Z","iopub.status.idle":"2024-05-29T07:29:21.292090Z","shell.execute_reply":"2024-05-29T07:29:21.291214Z","shell.execute_reply.started":"2024-05-29T07:29:21.273066Z"},"trusted":true},"outputs":[{"ename":"TypeError","evalue":"'collections.OrderedDict' object is not callable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test sentiment prediction\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe movie was great and I really enjoyed the performances of the actors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe movie was great and I really enjoyed the performances of the actors.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted sentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[1;32mIn[14], line 8\u001b[0m, in \u001b[0;36mpredict_sentiment\u001b[1;34m(text, model, tokenizer, device, max_length)\u001b[0m\n\u001b[0;32m      5\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 8\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m         _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds\n","\u001b[1;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"]}],"source":["# Test sentiment prediction\n","test_text = \"The movie was great and I really enjoyed the performances of the actors.\"\n","sentiment = predict_sentiment(test_text, model, tokenizer, device)\n","print(\"The movie was great and I really enjoyed the performances of the actors.\")\n","print(f\"Predicted sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T07:29:43.195802Z","iopub.status.busy":"2024-05-29T07:29:43.195429Z","iopub.status.idle":"2024-05-29T07:29:43.207606Z","shell.execute_reply":"2024-05-29T07:29:43.206628Z","shell.execute_reply.started":"2024-05-29T07:29:43.195768Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Language</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>تعرف على ما إذا كان شخص ما يقول نكتة رائعة يمك...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>هذا سؤال جيد.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>[23] عزا فريق في مركز بالو ألتو للأبحاث هذا ال...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>إنها جيدة بالنسبة لك ، سيكون أفضل بدونك وهذا م...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>تم تدوين سياسة ويكيبيديا الخاصة بـ \"وجهة نظر م...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9784</th>\n","      <td>طلب للحصول على معلومات.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9789</th>\n","      <td>للإجابة على سؤال واحد في الاختبار أو واجه الرج...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9801</th>\n","      <td>لا يهم مثل لا تقلق إذا أسقطت قهوتك فوقي.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9805</th>\n","      <td>من دواعي سروري.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9817</th>\n","      <td>تم استخدام مصطلح \"التعلم الآلي\" لأول مرة في عا...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>509 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   Text  Language\n","4     تعرف على ما إذا كان شخص ما يقول نكتة رائعة يمك...         0\n","16                                        هذا سؤال جيد.         0\n","17    [23] عزا فريق في مركز بالو ألتو للأبحاث هذا ال...         0\n","25    إنها جيدة بالنسبة لك ، سيكون أفضل بدونك وهذا م...         0\n","34    تم تدوين سياسة ويكيبيديا الخاصة بـ \"وجهة نظر م...         0\n","...                                                 ...       ...\n","9784                            طلب للحصول على معلومات.         0\n","9789  للإجابة على سؤال واحد في الاختبار أو واجه الرج...         0\n","9801           لا يهم مثل لا تقلق إذا أسقطت قهوتك فوقي.         0\n","9805                                    من دواعي سروري.         0\n","9817  تم استخدام مصطلح \"التعلم الآلي\" لأول مرة في عا...         0\n","\n","[509 rows x 2 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Test sentiment prediction\n","test_text = \"تعرف على ما إذا كان شخص ما يقول نكتة رائعة يمكن\"\n","sentiment = predict_sentiment(test_text, model, tokenizer, device)\n","print(\"The movie was great and I really enjoyed the performances of the actors.\")\n","print(f\"Predicted sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5100480,"sourceId":8538404,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
